# お勉強用メモ
備忘録的なやつ

## Few-Shot プロンプティング
Few-shotプロンプティングとは、**モデルに対して事前にいくつかの例を提示**し、結果を導き出す方法を学習させるプロンプトのこと。ChatGPTを含むLLMは、十分に学習されておりZero-Shotプロンプティングでも良い結果が得られることがあるが、プロンプトでいくつかの例（Few-Shot）を与えるFew-Shotプロンプティングを採用することで、より精度の高い結果が期待できる。
## Chain of Thought プロンプティング
中間的な推論ステップを設けてあげたり、仮説を示してやってLLMが考える文脈を準備することらしい。数学の問題とかはこれで結構精度が上がるらしい。
## LLMでのドキュメント検索
### エンジン検索
ドキュメントやそのメタデータをインデックス化してそれを検索する方法
### ベクトル検索
データ(文書)とプロンプトを全てベクトル化し、その類似度に基づいて検索する方法。具体的なベクトル化の手法としてはEmbeddingとかいうやつがあるらしい。類似度を確認するときはコサイン類似度が使われがち。
https://qiita.com/sakabe/items/5f14999ded1de087c9b5
## トークンとは
### 単語トークン
その名の通り単語の単位
### 文字トークン
単語の意味の単位を加味せず、１文字ずつ分割された単位
### サブワードトークン
文字と単語の中間くらいの単位らしい。こういう単位に分割する代表的な方法にByte-Pair Encoding（BPE）やSentencePieceなどがある。ちなみにGPTシリーズはこの方法を使っている。日本語はトークンが多くなりがちなのもこの辺が絡んでるとかなんとかだと思う。

## PaLM2
google様が開発した大規模言語モデル。
Codey for Code Generationなど派生も多く、コード生成っぽい話題が多め。